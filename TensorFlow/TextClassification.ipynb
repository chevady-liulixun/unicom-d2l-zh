{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 影评文本分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将文本形式的影评分为“正面”或“负面”，这是一个二元分类（又称为两类分类）的示例，也是一种重要且广泛适用的机器学习问题。\n",
    "将使用的[IMDB](https://www.tensorflow.org/api_docs/python/tf/keras/datasets/imdb?hl=zh_cn)数据集，其中包含来自[互联网电影数据库](https://www.imdb.com/)的 50000 条影评文本。影评书记将被拆分为训练集（25000 条影评）和测试集（25000 条影评）。训练集和测试集之间达成了平衡，意味着它们包含相同数量的正面和负面影评。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将被使用的是`tf.keras`，它是一种用于在TensorFlow中构建和训练模型的高阶 API。有关使用`tf.keras`的更高级文本分类教程，请参阅[MLCC文本分类指南](https://developers.google.com/machine-learning/guides/text-classification/?hl=zh_cn)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 下载 IMDB 数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow中包含IMDB数据集，并且已对该数据集进行了预处理，影评（字词序列）已经被转换为整数序列，其中每个整数表示字典中的一个特定字词。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下代码会将`IMDB数据集`下载到本地计算机上（如果已下载了该数据集，则会使用缓存副本）：☟"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 6s 0us/step\n"
     ]
    }
   ],
   "source": [
    "imdb = keras.datasets.imdb\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参数`num_words`=10000 会保留训练数据中出现频次在前 10000 位的字词。为确保数据规模处于可管理的水平，罕见字词将被舍弃。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 探索数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先了解一下数据的格式。该数据集已经过预处理：每个样本都是一个整数数组，表示影评中的字词。每个标签都是整数值 0 或 1，其中 0 表示负面影评，1 表示正面影评。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training entries: 25000, labels: 25000\n"
     ]
    }
   ],
   "source": [
    "print(\"Training entries: {}, labels: {}\".format(len(train_data), len(train_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "影评文本已转换为整数，其中每个整数都表示字典中的一个特定字词。第一条影评如下所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "影评的长度可能会有所不同。由于神经网络的输入必须具有相同长度，因此我们稍后需要解决此问题。以下代码显示了第一条和第二条影评中的字词数：☟"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(218, 189)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data[0]), len(train_data[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 将整数转换回字词"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "需要将整数转换回文本，以便阅读。在以下代码中，将创建一个辅助函数来查询包含整数到字符串映射的字典对象："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
      "1646592/1641221 [==============================] - 1s 1us/step\n"
     ]
    }
   ],
   "source": [
    "# A dictionary mapping words to an integer index\n",
    "word_index = imdb.get_word_index()\n",
    "\n",
    "# The first indices are reserved\n",
    "word_index = {k:(v+3) for k,v in word_index.items()}\n",
    "word_index[\"<PAD>\"] = 0\n",
    "word_index[\"<START>\"] = 1\n",
    "word_index[\"<UNK>\"] = 2  # unknown\n",
    "word_index[\"<UNUSED>\"] = 3\n",
    "\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "\n",
    "def decode_review(text):\n",
    "    return ' '.join([reverse_word_index.get(i, '?') for i in text])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在，可以使用`decode_review`函数显示第一条影评的文本：☟"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<START> this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNK> to the two little boy's that played the <UNK> of norman and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_review(train_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 准备数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "影评（整数数组）必须转换为张量，然后才能输入到神经网络中。以下两种方法可以实现这种转换：☟\n",
    "\n",
    "* 对数组进行[one-hot](https://zh.wikipedia.org/wiki/One-hot)编码，将它们转换为由 0 和 1 构成的向量。例如，序列 [3, 5] 将变成一个 10000 维的向量，除索引 3 和 5 转换为 1 之外，其余全转换为 0。然后，将它作为网络的第一层，一个可以处理浮点向量数据的密集层。不过，这种方法会占用大量内存，需要一个大小为`num_words * num_reviews`的矩阵。\n",
    "\n",
    "* 或者，我们可以填充数组，使它们都具有相同的长度，然后创建一个形状为`max_length * num_reviews`的整数张量。我们可以使用一个能够处理这种形状的嵌入层作为网络中的第一层。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将使用第二种方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于影评的长度必须相同，我们将使用`pad_sequences`函数将长度标准化："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = keras.preprocessing.sequence.pad_sequences(train_data,\n",
    "                                                        value=word_index[\"<PAD>\"],\n",
    "                                                        padding='post',\n",
    "                                                        maxlen=256)\n",
    "\n",
    "test_data = keras.preprocessing.sequence.pad_sequences(test_data,\n",
    "                                                       value=word_index[\"<PAD>\"],\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看样本的长度：☟"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 256)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data[0]), len(train_data[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看（现已填充的）第一条影评："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   1   14   22   16   43  530  973 1622 1385   65  458 4468   66 3941\n",
      "    4  173   36  256    5   25  100   43  838  112   50  670    2    9\n",
      "   35  480  284    5  150    4  172  112  167    2  336  385   39    4\n",
      "  172 4536 1111   17  546   38   13  447    4  192   50   16    6  147\n",
      " 2025   19   14   22    4 1920 4613  469    4   22   71   87   12   16\n",
      "   43  530   38   76   15   13 1247    4   22   17  515   17   12   16\n",
      "  626   18    2    5   62  386   12    8  316    8  106    5    4 2223\n",
      " 5244   16  480   66 3785   33    4  130   12   16   38  619    5   25\n",
      "  124   51   36  135   48   25 1415   33    6   22   12  215   28   77\n",
      "   52    5   14  407   16   82    2    8    4  107  117 5952   15  256\n",
      "    4    2    7 3766    5  723   36   71   43  530  476   26  400  317\n",
      "   46    7    4    2 1029   13  104   88    4  381   15  297   98   32\n",
      " 2071   56   26  141    6  194 7486   18    4  226   22   21  134  476\n",
      "   26  480    5  144   30 5535   18   51   36   28  224   92   25  104\n",
      "    4  226   65   16   38 1334   88   12   16  283    5   16 4472  113\n",
      "  103   32   15   16 5345   19  178   32    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构建模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "神经网络通过堆叠层创建而成，这需要做出两个架构方面的主要决策：\n",
    "\n",
    "* 要在模型中使用多少个层？\n",
    "* 要针对每个层使用多少个隐藏单元？\n",
    "\n",
    "在本示例中，输入数据由字词-索引数组构成。要预测的标签是 0 或 1。接下来，我们为此问题构建一个模型：☟"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Workplace\\OneDrive\\WindowsToolBox\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\keras\\initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Workplace\\OneDrive\\WindowsToolBox\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 16)          160000    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 160,289\n",
      "Trainable params: 160,289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# input shape is the vocabulary count used for the movie reviews (10,000 words)\n",
    "vocab_size = 10000\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, 16))\n",
    "model.add(keras.layers.GlobalAveragePooling1D())\n",
    "model.add(keras.layers.Dense(16, activation=tf.nn.relu))\n",
    "model.add(keras.layers.Dense(1, activation=tf.nn.sigmoid))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "按顺序堆叠各个层以构建分类器：\n",
    "\n",
    "1. 第一层是`Embedding`层。该层会在整数编码的词汇表中查找每个字词-索引的嵌入向量。模型在接受训练时会学习这些向量。这些向量会向输出数组添加一个维度。生成的维度为：`(batch, sequence, embedding)`。\n",
    "2. 接下来，一个`GlobalAveragePooling1D`层通过对序列维度求平均值，针对每个样本返回一个长度固定的输出向量。这样，模型便能够以尽可能简单的方式处理各种长度的输入。\n",
    "3. 该长度固定的输出向量会传入一个全连接`(Dense)`层（包含 16 个隐藏单元）。\n",
    "4. 最后一层与单个输出节点密集连接。应用`sigmoid`激活函数后，结果是介于 0 到 1 之间的浮点值，表示概率或置信水平。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 隐藏单元"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上述模型在输入和输出之间有两个中间层（也称为“隐藏”层）。输出（单元、节点或神经元）的数量是相应层的表示法空间的维度。换句话说，该数值表示学习内部表示法时网络所允许的自由度。\n",
    "\n",
    "如果模型具有更多隐藏单元（更高维度的表示空间）和/或更多层，则说明网络可以学习更复杂的表示法。不过，这会使网络耗费更多计算资源，并且可能导致学习不必要的模式（可以优化在训练数据上的表现，但不会优化在测试数据上的表现）。这称为**过拟合**，我们稍后会加以探讨。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 损失函数和优化器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型在训练时需要一个损失函数和一个优化器。由于这是一个二元分类问题且模型会输出一个概率（应用 S 型激活函数的单个单元层），因此我们将使用`binary_crossentropy`损失函数。\n",
    "\n",
    "该函数并不是唯一的损失函数，例如，您可以选择`mean_squared_error`。但一般来说，`binary_crossentropy`更适合处理概率问题，它可测量概率分布之间的“差距”，在本例中则为实际分布和预测之间的“差距”。\n",
    "\n",
    "稍后，在探索回归问题（比如预测房价）时，我们将了解如何使用另一个称为均方误差的损失函数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在，配置模型以使用优化器和损失函数：☟"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Workplace\\OneDrive\\WindowsToolBox\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=tf.train.AdamOptimizer(),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 创建验证集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在训练时，我们需要检查模型处理从未见过的数据的准确率。我们从原始训练数据中分离出10000个样本，创建一个验证集。（为什么现在不使用测试集？我们的目标是仅使用训练数据开发和调整模型，然后仅使用一次测试数据评估准确率。）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = train_data[:10000]\n",
    "partial_x_train = train_data[10000:]\n",
    "\n",
    "y_val = train_labels[:10000]\n",
    "partial_y_train = train_labels[10000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用有512个样本的小批次训练模型 40 个周期。这将对`x_train`和`y_train`张量中的所有样本进行 40 次迭代。在训练期间，监控模型在验证集的10000个样本上的损失和准确率："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/40\n",
      "15000/15000 [==============================] - 4s 262us/sample - loss: 0.6920 - acc: 0.5756 - val_loss: 0.6902 - val_acc: 0.6361\n",
      "Epoch 2/40\n",
      "15000/15000 [==============================] - 3s 184us/sample - loss: 0.6868 - acc: 0.7131 - val_loss: 0.6831 - val_acc: 0.7440\n",
      "Epoch 3/40\n",
      "15000/15000 [==============================] - 3s 194us/sample - loss: 0.6747 - acc: 0.7537 - val_loss: 0.6670 - val_acc: 0.7512\n",
      "Epoch 4/40\n",
      "15000/15000 [==============================] - 3s 178us/sample - loss: 0.6526 - acc: 0.7695 - val_loss: 0.6419 - val_acc: 0.7473\n",
      "Epoch 5/40\n",
      "15000/15000 [==============================] - 3s 190us/sample - loss: 0.6206 - acc: 0.7891 - val_loss: 0.6086 - val_acc: 0.7767\n",
      "Epoch 6/40\n",
      "15000/15000 [==============================] - 3s 181us/sample - loss: 0.5806 - acc: 0.8096 - val_loss: 0.5700 - val_acc: 0.8030\n",
      "Epoch 7/40\n",
      "15000/15000 [==============================] - 3s 182us/sample - loss: 0.5358 - acc: 0.8283 - val_loss: 0.5280 - val_acc: 0.8168\n",
      "Epoch 8/40\n",
      "15000/15000 [==============================] - 3s 178us/sample - loss: 0.4905 - acc: 0.8453 - val_loss: 0.4886 - val_acc: 0.8310\n",
      "Epoch 9/40\n",
      "15000/15000 [==============================] - 3s 179us/sample - loss: 0.4477 - acc: 0.8613 - val_loss: 0.4523 - val_acc: 0.8416\n",
      "Epoch 10/40\n",
      "15000/15000 [==============================] - 3s 183us/sample - loss: 0.4092 - acc: 0.8733 - val_loss: 0.4216 - val_acc: 0.8490\n",
      "Epoch 11/40\n",
      "15000/15000 [==============================] - 3s 178us/sample - loss: 0.3760 - acc: 0.8809 - val_loss: 0.3957 - val_acc: 0.8586\n",
      "Epoch 12/40\n",
      "15000/15000 [==============================] - 3s 227us/sample - loss: 0.3476 - acc: 0.8893 - val_loss: 0.3752 - val_acc: 0.8602\n",
      "Epoch 13/40\n",
      "15000/15000 [==============================] - 3s 217us/sample - loss: 0.3242 - acc: 0.8944 - val_loss: 0.3571 - val_acc: 0.8674\n",
      "Epoch 14/40\n",
      "15000/15000 [==============================] - 3s 184us/sample - loss: 0.3031 - acc: 0.8997 - val_loss: 0.3436 - val_acc: 0.8703\n",
      "Epoch 15/40\n",
      "15000/15000 [==============================] - 3s 183us/sample - loss: 0.2855 - acc: 0.9031 - val_loss: 0.3325 - val_acc: 0.8718\n",
      "Epoch 16/40\n",
      "15000/15000 [==============================] - 3s 226us/sample - loss: 0.2695 - acc: 0.9091 - val_loss: 0.3230 - val_acc: 0.8750\n",
      "Epoch 17/40\n",
      "15000/15000 [==============================] - 4s 278us/sample - loss: 0.2550 - acc: 0.9139 - val_loss: 0.3151 - val_acc: 0.8770\n",
      "Epoch 18/40\n",
      "15000/15000 [==============================] - 3s 233us/sample - loss: 0.2422 - acc: 0.9179 - val_loss: 0.3082 - val_acc: 0.8800\n",
      "Epoch 19/40\n",
      "15000/15000 [==============================] - 3s 182us/sample - loss: 0.2306 - acc: 0.9209 - val_loss: 0.3025 - val_acc: 0.8809\n",
      "Epoch 20/40\n",
      "15000/15000 [==============================] - 3s 185us/sample - loss: 0.2202 - acc: 0.9242 - val_loss: 0.2984 - val_acc: 0.8800\n",
      "Epoch 21/40\n",
      "15000/15000 [==============================] - 3s 170us/sample - loss: 0.2098 - acc: 0.9291 - val_loss: 0.2947 - val_acc: 0.8814\n",
      "Epoch 22/40\n",
      "15000/15000 [==============================] - 3s 185us/sample - loss: 0.2010 - acc: 0.9318 - val_loss: 0.2918 - val_acc: 0.8829\n",
      "Epoch 23/40\n",
      "15000/15000 [==============================] - 3s 178us/sample - loss: 0.1921 - acc: 0.9353 - val_loss: 0.2902 - val_acc: 0.8829\n",
      "Epoch 24/40\n",
      "15000/15000 [==============================] - 3s 197us/sample - loss: 0.1845 - acc: 0.9391 - val_loss: 0.2875 - val_acc: 0.8840\n",
      "Epoch 25/40\n",
      "15000/15000 [==============================] - 3s 192us/sample - loss: 0.1766 - acc: 0.9427 - val_loss: 0.2859 - val_acc: 0.8842\n",
      "Epoch 26/40\n",
      "15000/15000 [==============================] - 3s 193us/sample - loss: 0.1696 - acc: 0.9461 - val_loss: 0.2857 - val_acc: 0.8838\n",
      "Epoch 27/40\n",
      "15000/15000 [==============================] - 3s 170us/sample - loss: 0.1630 - acc: 0.9484 - val_loss: 0.2849 - val_acc: 0.8840\n",
      "Epoch 28/40\n",
      "15000/15000 [==============================] - 3s 172us/sample - loss: 0.1567 - acc: 0.9521 - val_loss: 0.2843 - val_acc: 0.8848\n",
      "Epoch 29/40\n",
      "15000/15000 [==============================] - 2s 160us/sample - loss: 0.1512 - acc: 0.9539 - val_loss: 0.2861 - val_acc: 0.8827\n",
      "Epoch 30/40\n",
      "15000/15000 [==============================] - 2s 159us/sample - loss: 0.1455 - acc: 0.9562 - val_loss: 0.2849 - val_acc: 0.8851\n",
      "Epoch 31/40\n",
      "15000/15000 [==============================] - 2s 164us/sample - loss: 0.1397 - acc: 0.9586 - val_loss: 0.2855 - val_acc: 0.8862\n",
      "Epoch 32/40\n",
      "15000/15000 [==============================] - 2s 164us/sample - loss: 0.1344 - acc: 0.9603 - val_loss: 0.2866 - val_acc: 0.8868\n",
      "Epoch 33/40\n",
      "15000/15000 [==============================] - 3s 179us/sample - loss: 0.1294 - acc: 0.9623 - val_loss: 0.2884 - val_acc: 0.8852\n",
      "Epoch 34/40\n",
      "15000/15000 [==============================] - 2s 159us/sample - loss: 0.1249 - acc: 0.9640 - val_loss: 0.2896 - val_acc: 0.8858\n",
      "Epoch 35/40\n",
      "15000/15000 [==============================] - 3s 170us/sample - loss: 0.1208 - acc: 0.9652 - val_loss: 0.2921 - val_acc: 0.8860\n",
      "Epoch 36/40\n",
      "15000/15000 [==============================] - 3s 186us/sample - loss: 0.1163 - acc: 0.9675 - val_loss: 0.2935 - val_acc: 0.8864\n",
      "Epoch 37/40\n",
      "15000/15000 [==============================] - 3s 194us/sample - loss: 0.1120 - acc: 0.9697 - val_loss: 0.2955 - val_acc: 0.8854\n",
      "Epoch 38/40\n",
      "15000/15000 [==============================] - 2s 157us/sample - loss: 0.1081 - acc: 0.9712 - val_loss: 0.2984 - val_acc: 0.8839\n",
      "Epoch 39/40\n",
      "15000/15000 [==============================] - 2s 162us/sample - loss: 0.1047 - acc: 0.9717 - val_loss: 0.3009 - val_acc: 0.8831\n",
      "Epoch 40/40\n",
      "15000/15000 [==============================] - 2s 163us/sample - loss: 0.1008 - acc: 0.9735 - val_loss: 0.3029 - val_acc: 0.8841\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=40,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 评估模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们来看看模型的表现如何。模型会返回两个值：损失（表示误差的数字，越低越好）和准确率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 2s 84us/sample - loss: 0.3236 - acc: 0.8736\n",
      "[0.32355306965351105, 0.8736]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(test_data, test_labels)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用这种相当简单的方法可实现约 87% 的准确率。如果采用更高级的方法，模型的准确率应该会接近 95%。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建准确率和损失随时间变化的图"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`model.fit()`返回一个`History`对象，该对象包含一个字典，其中包括训练期间发生的所有情况："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'acc', 'val_loss', 'val_acc'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一共有 4 个条目：每个条目对应训练和验证期间的一个受监控指标。我们可以使用这些指标绘制训练损失与验证损失图表以进行对比，并绘制训练准确率与验证准确率图表："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()   # clear figure\n",
    "acc_values = history_dict['acc']\n",
    "val_acc_values = history_dict['val_acc']\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在该图表中，圆点表示训练损失和准确率，实线表示验证损失和准确率。\n",
    "\n",
    "可以注意到，训练损失随着周期数的增加而降低，训练准确率随着周期数的增加而提高。在使用梯度下降法优化模型时，这属于正常现象 - 该方法应在每次迭代时尽可能降低目标值。\n",
    "\n",
    "验证损失和准确率的变化情况并非如此，它们似乎在大约 20 个周期后达到峰值。这是一种过拟合现象：模型在训练数据上的表现要优于在从未见过的数据上的表现。在此之后，模型会过度优化和学习特定于训练数据的表示法，而无法泛化到测试数据。\n",
    "\n",
    "对于这种特殊情况，我们可以在大约 20 个周期后停止训练，防止出现过拟合。稍后，您将了解如何使用回调自动执行此操作。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
