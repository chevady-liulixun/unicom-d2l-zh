{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 数据操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T02:10:59.621604Z",
     "start_time": "2019-10-16T02:10:56.529037Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.0+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.manual_seed(0) # 生成随机数用的种子\n",
    "torch.cuda.manual_seed(0)\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[`torch.manual_seed()`](https://pytorch.org/docs/stable/torch.html#torch._C.Generator.manual_seed)的作用是设置用于生成随机数的种子。\n",
    "[`torch.cuda.manual_seed()`](https://pytorch.org/docs/stable/cuda.html#torch.cuda.manual_seed)作用与`torch.manual_seed()`相同，只不过是在当前GPU上执行，如果不可执行，比如根本就没有GPU，那么它也不报错。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.1 创建`Tensor`\n",
    "\n",
    "创建一个5x3的未初始化的`Tensor`："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T02:13:42.927209Z",
     "start_time": "2019-10-16T02:13:42.759664Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0102e-38, 8.9082e-39, 9.9184e-39],\n",
      "        [9.0000e-39, 1.0561e-38, 1.0653e-38],\n",
      "        [4.1327e-39, 8.9082e-39, 9.8265e-39],\n",
      "        [9.4592e-39, 1.0561e-38, 1.0653e-38],\n",
      "        [1.0469e-38, 9.5510e-39, 4.2244e-39]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建一个5x3的随机初始化的`Tensor`:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T02:14:05.345989Z",
     "start_time": "2019-10-16T02:14:05.299333Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4963, 0.7682, 0.0885],\n",
      "        [0.1320, 0.3074, 0.6341],\n",
      "        [0.4901, 0.8964, 0.4556],\n",
      "        [0.6323, 0.3489, 0.4017],\n",
      "        [0.0223, 0.1689, 0.2939]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[torch.rand](https://pytorch.org/docs/stable/torch.html#torch.rand)是一个均匀分布在$[0,1)$的随机数数组。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建一个5x3的long型全0的`Tensor`:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T02:18:46.825653Z",
     "start_time": "2019-10-16T02:18:46.762981Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(5, 3, dtype=torch.long)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "直接根据数据创建:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T02:19:10.835266Z",
     "start_time": "2019-10-16T02:19:10.801704Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.5000, 3.0000])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([5.5, 3])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "还可以通过现有的`Tensor`来创建，此方法会默认重用输入`Tensor`的一些属性，例如数据类型，除非自定义数据类型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T02:22:54.921178Z",
     "start_time": "2019-10-16T02:22:54.858693Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n",
      "tensor([[ 2.3466, -1.1088,  1.6254],\n",
      "        [ 1.2333, -0.1832, -1.3140],\n",
      "        [-1.6894,  1.2525, -0.5545],\n",
      "        [ 0.3019,  1.1295,  1.7179],\n",
      "        [-0.8507, -0.8486, -0.1848]])\n"
     ]
    }
   ],
   "source": [
    "x = x.new_ones(5, 3, dtype=torch.float64)      # 返回的tensor默认具有相同的torch.dtype和torch.device\n",
    "print(x)\n",
    "\n",
    "x = torch.randn_like(x, dtype=torch.float)    # 指定新的数据类型\n",
    "print(x)                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T02:22:56.058154Z",
     "start_time": "2019-10-16T02:22:55.901931Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[8, 7],\n",
       "        [7, 8]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randint(3, 10, (2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T02:23:00.393759Z",
     "start_time": "2019-10-16T02:23:00.362234Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2706,  0.0193,  0.8868,  0.0552],\n",
       "        [ 0.6880,  1.2326,  1.1580,  0.1673],\n",
       "        [-1.5773,  1.0689, -0.5065, -1.4561]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.normal(0, 1, size=(3, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T02:23:09.736389Z",
     "start_time": "2019-10-16T02:23:09.705147Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.2925, -0.0971,  1.1643, -0.6928],\n",
       "        [-0.9871,  1.0057, -0.4409, -0.4514],\n",
       "        [ 0.7020, -0.2345,  1.1007, -0.8789]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(3,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以通过`shape`或者`size()`来获取`Tensor`的形状:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T02:24:16.825758Z",
     "start_time": "2019-10-16T02:24:16.794929Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n",
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "print(x.size())\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 注意：返回的torch.Size其实就是一个tuple, 支持所有tuple的操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T02:24:20.382953Z",
     "start_time": "2019-10-16T02:24:20.320435Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3., 4., 5., 6., 7.])\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])\n"
     ]
    }
   ],
   "source": [
    "x1 = torch.arange(1., 8) \n",
    "print(x1) \n",
    "x2= torch.arange(12) \n",
    "print(x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.2 操作\n",
    "### 算术操作\n",
    "* **加法形式一**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T02:24:24.806045Z",
     "start_time": "2019-10-16T02:24:24.774754Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 1, 1, 1],\n",
       "         [1, 1, 1, 2],\n",
       "         [1, 2, 2, 0]],\n",
       "\n",
       "        [[1, 0, 1, 0],\n",
       "         [0, 0, 1, 0],\n",
       "         [2, 1, 1, 0]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randint(0,3,(2,3,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T02:25:34.327517Z",
     "start_time": "2019-10-16T02:25:34.265027Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 0, 1],\n",
      "        [2, 1, 2],\n",
      "        [2, 2, 2],\n",
      "        [1, 2, 2],\n",
      "        [2, 2, 0]])\n",
      "tensor([[0, 0, 1],\n",
      "        [0, 1, 0],\n",
      "        [1, 0, 1],\n",
      "        [0, 1, 0],\n",
      "        [0, 0, 1]])\n",
      "tensor([[1, 0, 2],\n",
      "        [2, 2, 2],\n",
      "        [3, 2, 3],\n",
      "        [1, 3, 2],\n",
      "        [2, 2, 1]])\n"
     ]
    }
   ],
   "source": [
    "x=torch.randint(0,3,(5,3))\n",
    "print(x)\n",
    "y = torch.randint(0,2,(5, 3))\n",
    "print(y)\n",
    "print(x + y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **加法形式二**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T02:25:42.389096Z",
     "start_time": "2019-10-16T02:25:42.357813Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 0, 2],\n",
      "        [2, 2, 2],\n",
      "        [3, 2, 3],\n",
      "        [1, 3, 2],\n",
      "        [2, 2, 1]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.add(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T02:25:59.759908Z",
     "start_time": "2019-10-16T02:25:59.697364Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 0, 2],\n",
      "        [2, 2, 2],\n",
      "        [3, 2, 3],\n",
      "        [1, 3, 2],\n",
      "        [2, 2, 1]])\n",
      "tensor([[1, 0, 1],\n",
      "        [2, 1, 2],\n",
      "        [2, 2, 2],\n",
      "        [1, 2, 2],\n",
      "        [2, 2, 0]])\n",
      "tensor([[0, 0, 1],\n",
      "        [0, 1, 0],\n",
      "        [1, 0, 1],\n",
      "        [0, 1, 0],\n",
      "        [0, 0, 1]])\n",
      "tensor([[1, 0, 2],\n",
      "        [2, 2, 2],\n",
      "        [3, 2, 3],\n",
      "        [1, 3, 2],\n",
      "        [2, 2, 1]])\n"
     ]
    }
   ],
   "source": [
    "result = torch.empty((5, 3), dtype=torch.int64)\n",
    "print(result)\n",
    "print(x)\n",
    "print(y)\n",
    "torch.add(x, y, out=result)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **加法形式三、inplace**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T02:26:05.840676Z",
     "start_time": "2019-10-16T02:26:05.809435Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 0, 2],\n",
      "        [2, 2, 2],\n",
      "        [3, 2, 3],\n",
      "        [1, 3, 2],\n",
      "        [2, 2, 1]])\n"
     ]
    }
   ],
   "source": [
    "# adds x to y\n",
    "y.add_(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **注：PyTorch操作inplace版本都有后缀\"_\", 例如`x.copy_(y), x.t_()`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 按元素乘法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T02:26:16.504805Z",
     "start_time": "2019-10-16T02:26:16.440945Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 0, 1],\n",
      "        [2, 1, 2],\n",
      "        [2, 2, 2],\n",
      "        [1, 2, 2],\n",
      "        [2, 2, 0]])\n",
      "tensor([[1, 0, 2],\n",
      "        [2, 2, 2],\n",
      "        [3, 2, 3],\n",
      "        [1, 3, 2],\n",
      "        [2, 2, 1]])\n",
      "tensor([[1, 0, 2],\n",
      "        [4, 2, 4],\n",
      "        [6, 4, 6],\n",
      "        [1, 6, 4],\n",
      "        [4, 4, 0]])\n",
      "tensor([[2, 0, 2],\n",
      "        [4, 2, 4],\n",
      "        [4, 4, 4],\n",
      "        [2, 4, 4],\n",
      "        [4, 4, 0]])\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(y)\n",
    "print(x*y)\n",
    "print(x*2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 按元素除法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T02:26:23.731270Z",
     "start_time": "2019-10-16T02:26:23.668820Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 1., 2.],\n",
      "        [3., 2., 3.],\n",
      "        [3., 3., 3.],\n",
      "        [2., 3., 3.],\n",
      "        [3., 3., 1.]], dtype=torch.float64)\n",
      "tensor([[2., 1., 3.],\n",
      "        [3., 3., 3.],\n",
      "        [4., 3., 4.],\n",
      "        [2., 4., 3.],\n",
      "        [3., 3., 2.]], dtype=torch.float64)\n",
      "tensor([[1.0000, 1.0000, 0.6667],\n",
      "        [1.0000, 0.6667, 1.0000],\n",
      "        [0.7500, 1.0000, 0.7500],\n",
      "        [1.0000, 0.7500, 1.0000],\n",
      "        [1.0000, 1.0000, 0.5000]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "test_divide_x = (x+1).to(dtype=torch.float64)\n",
    "print(test_divide_x)\n",
    "test_divide_y = (y+1).to(dtype=torch.float64)\n",
    "print(test_divide_y)\n",
    "print(test_divide_x/test_divide_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 减法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T02:26:26.308123Z",
     "start_time": "2019-10-16T02:26:26.261257Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 0, 1],\n",
      "        [2, 1, 2],\n",
      "        [2, 2, 2],\n",
      "        [1, 2, 2],\n",
      "        [2, 2, 0]])\n",
      "tensor([[1, 0, 2],\n",
      "        [2, 2, 2],\n",
      "        [3, 2, 3],\n",
      "        [1, 3, 2],\n",
      "        [2, 2, 1]])\n",
      "tensor([[ 0,  0, -1],\n",
      "        [ 0, -1,  0],\n",
      "        [-1,  0, -1],\n",
      "        [ 0, -1,  0],\n",
      "        [ 0,  0, -1]])\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(y)\n",
    "print(x-y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 按元素做指数运算："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T02:26:38.911279Z",
     "start_time": "2019-10-16T02:26:38.880032Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 0, 1],\n",
      "        [2, 1, 2],\n",
      "        [2, 2, 2],\n",
      "        [1, 2, 2],\n",
      "        [2, 2, 0]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[2.7183, 1.0000, 2.7183],\n",
       "        [7.3891, 2.7183, 7.3891],\n",
       "        [7.3891, 7.3891, 7.3891],\n",
       "        [2.7183, 7.3891, 7.3891],\n",
       "        [7.3891, 7.3891, 1.0000]], dtype=torch.float64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x)\n",
    "e=x.to(dtype=torch.float64)#把x转换成浮点\n",
    "e.exp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 矩阵乘法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T02:28:14.688323Z",
     "start_time": "2019-10-16T02:28:14.618926Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 0, 1],\n",
      "        [2, 1, 2],\n",
      "        [2, 2, 2],\n",
      "        [1, 2, 2],\n",
      "        [2, 2, 0]])\n",
      "tensor([[1, 0, 2],\n",
      "        [2, 2, 2],\n",
      "        [3, 2, 3],\n",
      "        [1, 3, 2],\n",
      "        [2, 2, 1]])\n",
      "tensor([[1, 2, 3, 1, 2],\n",
      "        [0, 2, 2, 3, 2],\n",
      "        [2, 2, 3, 2, 1]])\n",
      "torch.Size([5, 3])\n",
      "torch.Size([3, 5])\n",
      "tensor([[ 3,  4,  6,  3,  3],\n",
      "        [ 6, 10, 14,  9,  8],\n",
      "        [ 6, 12, 16, 12, 10],\n",
      "        [ 5, 10, 13, 11,  8],\n",
      "        [ 2,  8, 10,  8,  8]])\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(y)\n",
    "print(y.T)\n",
    "print(y.shape)\n",
    "print(y.T.shape)\n",
    "torch.dot(torch.tensor([2, 3]), torch.tensor([2, 1]))\n",
    "#print(torch.matmul(x,y.T))\n",
    "print(torch.mm(x,y.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 矩阵的联结："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T02:29:36.848221Z",
     "start_time": "2019-10-16T02:29:36.789649Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 0, 1],\n",
      "        [2, 1, 2],\n",
      "        [2, 2, 2],\n",
      "        [1, 2, 2],\n",
      "        [2, 2, 0]])\n",
      "tensor([[1, 0, 2],\n",
      "        [2, 2, 2],\n",
      "        [3, 2, 3],\n",
      "        [1, 3, 2],\n",
      "        [2, 2, 1]])\n",
      "tensor([[1, 0, 1],\n",
      "        [2, 1, 2],\n",
      "        [2, 2, 2],\n",
      "        [1, 2, 2],\n",
      "        [2, 2, 0],\n",
      "        [1, 0, 2],\n",
      "        [2, 2, 2],\n",
      "        [3, 2, 3],\n",
      "        [1, 3, 2],\n",
      "        [2, 2, 1]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 1, 1, 0, 2],\n",
       "        [2, 1, 2, 2, 2, 2],\n",
       "        [2, 2, 2, 3, 2, 3],\n",
       "        [1, 2, 2, 1, 3, 2],\n",
       "        [2, 2, 0, 2, 2, 1]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x)\n",
    "print(y)\n",
    "print(torch.cat((x,y),0))\n",
    "torch.cat((x,y),1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####   判断："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T02:29:50.192444Z",
     "start_time": "2019-10-16T02:29:50.150603Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True,  True, False],\n",
       "        [ True, False,  True],\n",
       "        [False,  True, False],\n",
       "        [ True, False,  True],\n",
       "        [ True,  True, False]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x == y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 求和："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T02:30:00.711733Z",
     "start_time": "2019-10-16T02:30:00.664895Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(22)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 范数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T02:31:16.312126Z",
     "start_time": "2019-10-16T02:31:16.265257Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-4., -3., -2., -1.,  0.,  1.,  2.,  3.,  4.])\n",
      "tensor([[-4., -3., -2.],\n",
      "        [-1.,  0.,  1.],\n",
      "        [ 2.,  3.,  4.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(7.7460)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(9, dtype= torch.float) - 4\n",
    "print(a)\n",
    "b = a.reshape((3, 3))\n",
    "print(b)\n",
    "torch.norm(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 2],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 2],\n",
      "        [1, 2, 2]])\n",
      "tensor([[1., 1., 2.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 2.],\n",
      "        [1., 2., 2.]])\n",
      "tensor(5.1962)\n",
      "tensor([5., 6., 8.])\n",
      "tensor([4., 3., 3., 4., 5.])\n",
      "5.196152210235596\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "test_norm_x = x.to(dtype= torch.float)\n",
    "print(test_norm_x)\n",
    "print(torch.norm(test_norm_x))\n",
    "print(torch.norm(test_norm_x,p=1,dim=0))\n",
    "print(torch.norm(test_norm_x,p=1,dim=1))\n",
    "print(torch.norm(test_norm_x).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])\n",
      "torch.Size([12])\n",
      "tensor([[[ 0,  1,  2],\n",
      "         [ 3,  4,  5]],\n",
      "\n",
      "        [[ 6,  7,  8],\n",
      "         [ 9, 10, 11]]])\n",
      "tensor(11)\n",
      "tensor([[ 3.,  5.,  7.],\n",
      "        [15., 17., 19.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "a = torch.arange(12)\n",
    "print(a)\n",
    "print(a.shape)\n",
    "b = a.view(2,2,3)\n",
    "print(b)\n",
    "print(b[1,1,2])\n",
    "print(torch.norm(b.to(dtype=torch.float64), p=1, dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 索引\n",
    "\n",
    "在`Tensor`中，索引（index）代表了元素的位置。`Tensor`的索引从0（第1）开始逐一递增。例如，一个3行2列的矩阵的行索引分别为0、1和2，列索引分别为0和1。\n",
    "\n",
    "在下面的例子中，我们指定了`Tensor`的行索引截取范围`[1:4]`。依据**左闭右开**（数学表示成\\[1,4)）指定范围的惯例，它截取了矩阵`X`中行索引为1和3（即第2到第4行）的两行。\n",
    "\n",
    "这种与类似NumPy的索引方式，也可以用来操作来访问`Tensor`的一部分，需要注意的是：**索引出来的结果与原数据共享内存，也即修改一个，另一个会跟着修改。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T02:39:27.890718Z",
     "start_time": "2019-10-16T02:39:27.796985Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 0, 1],\n",
      "        [2, 1, 2],\n",
      "        [2, 2, 2],\n",
      "        [1, 2, 2],\n",
      "        [2, 2, 0]])\n",
      "tensor(2)\n",
      "tensor(2)\n",
      "tensor([[2, 1, 2],\n",
      "        [2, 2, 2],\n",
      "        [1, 2, 2]])\n",
      "tensor([2, 1, 2])\n",
      "tensor([2, 1, 2])\n",
      "tensor([[2, 1, 2],\n",
      "        [2, 1, 2],\n",
      "        [2, 2, 2],\n",
      "        [1, 2, 2],\n",
      "        [2, 2, 0]])\n"
     ]
    }
   ],
   "source": [
    "print(x) # x是一个5*3的数组\n",
    "print(x[3,2]) # 第4行，第3列的元素\n",
    "print(x[2, -2]) #-2就是倒数第2个元素=3,4\n",
    "print(x[1:4, :]) # 第2行和第5行\n",
    "y = x[0, :] # 第1行的所有元素\n",
    "y += 1\n",
    "print(y)\n",
    "print(x[0, :]) # 源tensor也被改了\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 改变形状\n",
    "用`view()`来改变`Tensor`的形状："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T02:40:03.844541Z",
     "start_time": "2019-10-16T02:40:03.803359Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3]) torch.Size([15]) torch.Size([3, 5])\n"
     ]
    }
   ],
   "source": [
    "y = x.view(15)\n",
    "z = x.view(-1, 5)  # -1所指的维度可以根据其他维度的值推出来\n",
    "print(x.size(), y.size(), z.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**注意`view()`返回的新tensor与源tensor共享内存，也即更改其中的一个，另外一个也会跟着改变。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T02:40:06.235097Z",
     "start_time": "2019-10-16T02:40:06.200916Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3, 2, 3],\n",
      "        [3, 2, 3],\n",
      "        [3, 3, 3],\n",
      "        [2, 3, 3],\n",
      "        [3, 3, 1]])\n",
      "tensor([3, 2, 3, 3, 2, 3, 3, 3, 3, 2, 3, 3, 3, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "x += 1\n",
    "print(x)\n",
    "print(y) # 也加了1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果不想共享内存，推荐先用`clone`创造一个副本然后再使用`view`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T02:40:09.966853Z",
     "start_time": "2019-10-16T02:40:09.919473Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2, 1, 2],\n",
      "        [2, 1, 2],\n",
      "        [2, 2, 2],\n",
      "        [1, 2, 2],\n",
      "        [2, 2, 0]])\n",
      "tensor([3, 2, 3, 3, 2, 3, 3, 3, 3, 2, 3, 3, 3, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "x_cp = x.clone().view(15)\n",
    "x -= 1\n",
    "print(x)\n",
    "print(x_cp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "另外一个常用的函数就是`item()`, 它可以将一个标量`Tensor`转换成一个Python number："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T02:40:36.569509Z",
     "start_time": "2019-10-16T02:40:36.538254Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4246])\n",
      "0.4245716631412506\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1)\n",
    "print(x)\n",
    "print(x.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.3 广播机制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2]])\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3]])\n",
      "tensor([[2, 3],\n",
      "        [3, 4],\n",
      "        [4, 5]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(1, 3).view(1, 2)\n",
    "print(x)\n",
    "y = torch.arange(1, 4).view(3, 1)\n",
    "print(y)\n",
    "print(x + y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.4 运算的内存开销"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1, 2])\n",
    "y = torch.tensor([3, 4])\n",
    "id_before = id(y)\n",
    "y = y + x\n",
    "print(id(y) == id_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1, 2])\n",
    "y = torch.tensor([3, 4])\n",
    "id_before = id(y)\n",
    "y[:] = y + x\n",
    "print(id(y) == id_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1, 2])\n",
    "y = torch.tensor([3, 4])\n",
    "id_before = id(y)\n",
    "torch.add(x, y, out=y) # y += x, y.add_(x)\n",
    "print(id(y) == id_before)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.5 `Tensor`和NumPy相互转换\n",
    "**`numpy()`和`from_numpy()`这两个函数产生的`Tensor`和NumPy array实际是使用的相同的内存，改变其中一个时另一个也会改变！！！**\n",
    "### `Tensor`转NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.]) [1. 1. 1. 1. 1.]\n",
      "tensor([2., 2., 2., 2., 2.]) [2. 2. 2. 2. 2.]\n",
      "tensor([3., 3., 3., 3., 3.]) [3. 3. 3. 3. 3.]\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "b = a.numpy()\n",
    "print(a, b)\n",
    "\n",
    "a += 1\n",
    "print(a, b)\n",
    "b += 1\n",
    "print(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NumPy数组转`Tensor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.] tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
      "[2. 2. 2. 2. 2.] tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
      "[3. 3. 3. 3. 3.] tensor([3., 3., 3., 3., 3.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "print(a, b)\n",
    "\n",
    "a += 1\n",
    "print(a, b)\n",
    "b += 1\n",
    "print(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "直接用`torch.tensor()`将NumPy数组转换成`Tensor`，该方法总是会进行数据拷贝，返回的`Tensor`和原来的数据不再共享内存。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4. 4. 4. 4. 4.] tensor([3., 3., 3., 3., 3.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# 用torch.tensor()转换时不会共享内存\n",
    "c = torch.tensor(a)\n",
    "a += 1\n",
    "print(a, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.6 `Tensor` on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以下代码只有在PyTorch GPU版本上才会执行\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # GPU\n",
    "    y = torch.ones_like(x, device=device)  # 直接创建一个在GPU上的Tensor\n",
    "    x = x.to(device)                       # 等价于 .to(\"cuda\")\n",
    "    z = x + y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\", torch.double))       # to()还可以同时更改数据类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
