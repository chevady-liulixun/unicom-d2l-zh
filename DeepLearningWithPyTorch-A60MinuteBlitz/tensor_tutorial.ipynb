{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "What is PyTorch?【PyTorch简介】\n",
    "============================\n",
    "\n",
    "It’s a Python-based scientific computing package targeted at two sets of\n",
    "audiences:\n",
    "\n",
    "-  A replacement for NumPy to use the power of GPUs\n",
    "-  a deep learning research platform that provides maximum flexibility\n",
    "   and speed\n",
    "\n",
    "Getting Started\n",
    "---------------\n",
    "\n",
    "Tensors【张量】\n",
    "^^^^^^^\n",
    "\n",
    "Tensors are similar to NumPy’s ndarrays, with the addition being that\n",
    "Tensors can also be used on a GPU to accelerate computing.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><h4>Note【未初始化矩阵】</h4><p>An uninitialized matrix is declared,\n",
    "    but does not contain definite known\n",
    "    values before it is used. When an\n",
    "    uninitialized matrix is created,\n",
    "    whatever values were in the allocated\n",
    "    memory at the time will appear as the initial values.</p></div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a 5x3 matrix, uninitialized:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a randomly initialized matrix:【随机数矩阵】\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0706, 0.2197, 0.1725],\n",
      "        [0.7586, 0.2165, 0.9523],\n",
      "        [0.6021, 0.6243, 0.2966],\n",
      "        [0.9431, 0.9925, 0.7690],\n",
      "        [0.4781, 0.6032, 0.6833]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a matrix filled zeros and of dtype long:\n",
    "【torch.dtype】：https://pytorch.org/docs/stable/tensor_attributes.html#torch.torch.dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(5, 3, dtype=torch.long)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a tensor directly from data:【直接创建一个张量】"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.5000, 3.0000])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([5.5, 3])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or create a tensor based on an existing tensor. These methods\n",
    "will reuse properties of the input tensor, e.g. dtype, unless\n",
    "new values are provided by user\n",
    "【由一个已存在的张量去创建一个新张量】\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n",
      "tensor([[ 1.9683e-01,  5.7029e-01,  1.6066e+00],\n",
      "        [ 1.2457e+00, -1.3981e+00,  1.8155e-01],\n",
      "        [-5.5024e-04,  2.2003e-01, -3.0950e-01],\n",
      "        [ 3.4499e-01, -1.2634e-01, -2.9506e+00],\n",
      "        [ 1.5725e+00,  1.5063e+00,  4.7864e-01]])\n"
     ]
    }
   ],
   "source": [
    "x = x.new_ones(5, 3, dtype=torch.double)      # new_* methods take in sizes\n",
    "print(x)\n",
    "\n",
    "x = torch.randn_like(x, dtype=torch.float)    # override dtype!\n",
    "print(x)                                      # result has the same size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "科学记数法的形式是由两个数的乘积组成的。表示为a×10^b（aEb）\n",
    "\n",
    "Get its size:【获取张量的形状大小】\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "print(x.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><h4>Note</h4><p>``torch.Size`` is in fact a tuple, so it supports all tuple operations.【矩阵运算】</p></div>\n",
    "\n",
    "Operations\n",
    "^^^^^^^^^^\n",
    "There are multiple syntaxes for operations. In the following\n",
    "example, we will take a look at the addition operation.\n",
    "\n",
    "Addition: syntax 1 【矩阵加法】\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3, 3, 4],\n",
      "        [4, 4, 3],\n",
      "        [4, 4, 4],\n",
      "        [3, 4, 3],\n",
      "        [3, 3, 4]])\n",
      "tensor([[1, 0, 1],\n",
      "        [0, 1, 0],\n",
      "        [1, 1, 1],\n",
      "        [0, 1, 0],\n",
      "        [1, 0, 0]])\n",
      "tensor([[4, 3, 5],\n",
      "        [4, 5, 3],\n",
      "        [5, 5, 5],\n",
      "        [3, 5, 3],\n",
      "        [4, 3, 4]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randint(3, 5, (5, 3))\n",
    "y = torch.randint(2, (5, 3))\n",
    "print(x)\n",
    "print(y)\n",
    "print(x + y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Addition: syntax 2 【torch.add()】：https://pytorch.org/docs/stable/torch.html#torch.add\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4, 3, 5],\n",
      "        [4, 5, 3],\n",
      "        [5, 5, 5],\n",
      "        [3, 5, 3],\n",
      "        [4, 3, 4]])\n",
      "tensor([[4, 3, 5],\n",
      "        [4, 5, 3],\n",
      "        [5, 5, 5],\n",
      "        [3, 5, 3],\n",
      "        [4, 3, 4]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.add(x, y))\n",
    "print(torch.add(x, 1, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Addition: providing an output tensor as argument\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5229, 0.1233, 0.9396],\n",
      "        [0.8145, 0.7490, 0.2626],\n",
      "        [0.3590, 0.4251, 0.5955],\n",
      "        [0.9824, 0.7877, 0.8401],\n",
      "        [0.9963, 0.8700, 0.6272]])\n",
      "tensor([[0.0728, 0.4706, 0.8685],\n",
      "        [0.5591, 0.1267, 0.4796],\n",
      "        [0.3089, 0.7920, 0.9171],\n",
      "        [0.8974, 0.5827, 0.3411],\n",
      "        [0.9290, 0.8472, 0.5775]])\n",
      "tensor([[0.5957, 0.5940, 1.8081],\n",
      "        [1.3736, 0.8756, 0.7422],\n",
      "        [0.6679, 1.2170, 1.5127],\n",
      "        [1.8799, 1.3704, 1.1812],\n",
      "        [1.9253, 1.7173, 1.2047]])\n",
      "tensor([[0.5957, 0.5940, 1.8081],\n",
      "        [1.3736, 0.8756, 0.7422],\n",
      "        [0.6679, 1.2170, 1.5127],\n",
      "        [1.8799, 1.3704, 1.1812],\n",
      "        [1.9253, 1.7173, 1.2047]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5, 3)\n",
    "print(x)\n",
    "y = torch.rand(5, 3)\n",
    "print(y)\n",
    "print(torch.add(x, y))\n",
    "result = torch.empty(5, 3)\n",
    "torch.add(x, y, out=result)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Addition: in-place\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3, 4, 3],\n",
      "        [4, 4, 3],\n",
      "        [4, 3, 3],\n",
      "        [4, 4, 4],\n",
      "        [3, 3, 4]])\n",
      "tensor([[0, 1, 1],\n",
      "        [1, 0, 0],\n",
      "        [0, 0, 1],\n",
      "        [0, 0, 1],\n",
      "        [1, 1, 1]])\n",
      "tensor([[3, 5, 4],\n",
      "        [5, 4, 3],\n",
      "        [4, 3, 4],\n",
      "        [4, 4, 5],\n",
      "        [4, 4, 5]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randint(3, 5, (5, 3))\n",
    "y = torch.randint(2, (5, 3))\n",
    "print(x)\n",
    "print(y)\n",
    "# adds x to y\n",
    "y.add_(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <div class=\"alert alert-info\"><h4>Note</h4><p>Any operation that mutates a tensor in-place is post-fixed with an ``_``.\n",
    "    For example: ``x.copy_(y)``, ``x.t_()``, will change ``x``.</p></div>\n",
    "\n",
    "You can use standard NumPy-like indexing with all bells and whistles!【获取x的第1（下标为0）列】\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 4, 4, 4, 3])\n"
     ]
    }
   ],
   "source": [
    "print(x[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resizing【改变张量形状】: If you want to resize/reshape tensor, you can use ``torch.view``:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.0192,  0.2842,  1.4595,  0.5467],\n",
      "        [ 0.7554, -1.1175,  1.0663, -0.1409],\n",
      "        [ 1.6339,  0.2263, -1.3486,  0.2586],\n",
      "        [ 0.0101, -0.9496,  1.8247, -0.5738]])\n",
      "tensor([-1.0192,  0.2842,  1.4595,  0.5467,  0.7554, -1.1175,  1.0663, -0.1409,\n",
      "         1.6339,  0.2263, -1.3486,  0.2586,  0.0101, -0.9496,  1.8247, -0.5738])\n",
      "tensor([[-1.0192,  0.2842,  1.4595,  0.5467,  0.7554, -1.1175,  1.0663, -0.1409],\n",
      "        [ 1.6339,  0.2263, -1.3486,  0.2586,  0.0101, -0.9496,  1.8247, -0.5738]])\n",
      "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4, 4)\n",
    "print(x)\n",
    "y = x.view(16)\n",
    "print(y)\n",
    "z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
    "print(z)\n",
    "print(x.size(), y.size(), z.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have a one element tensor, use ``.item()`` to get the value as a\n",
    "Python number\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.9374])\n",
      "1.9374208450317383\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1)\n",
    "print(x)\n",
    "print(x.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read later:**\n",
    "\n",
    "\n",
    "  100+ Tensor operations, including transposing, indexing, slicing,\n",
    "  mathematical operations, linear algebra, random numbers, etc.,\n",
    "  are described\n",
    "  `here <https://pytorch.org/docs/torch>`_.\n",
    "\n",
    "NumPy Bridge\n",
    "------------\n",
    "\n",
    "Converting a Torch Tensor to a NumPy array and vice versa is a breeze.\n",
    "\n",
    "【注意】The Torch Tensor and NumPy array will share their underlying memory\n",
    "locations (if the Torch Tensor is on CPU), and changing one will change\n",
    "the other.\n",
    "\n",
    "Converting a Torch Tensor to a NumPy Array\n",
    "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "b = a.numpy()\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See how the numpy array changed in value.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 2., 2., 2., 2.])\n",
      "[2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "a.add_(1)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting NumPy Array to Torch Tensor\n",
    "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "See how changing the np array changed the Torch Tensor automatically\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "np.add(a, 1, out=a)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the Tensors on the CPU except a CharTensor support converting to\n",
    "NumPy and back.\n",
    "\n",
    "CUDA Tensors\n",
    "------------\n",
    "\n",
    "Tensors can be moved onto any device using the ``.to`` method.【需要有GPU支持】【演示上阿里云】\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us run this cell only if CUDA is available\n",
    "# We will use ``torch.device`` objects to move tensors in and out of GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # a CUDA device object\n",
    "    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n",
    "    x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n",
    "    z = x + y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\", torch.double))       # ``.to`` can also change dtype together!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
