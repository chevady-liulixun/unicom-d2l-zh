{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch的RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "```\n",
    "class torch.nn.RNN(*args, **kwargs)\n",
    "```\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applies a multi-layer Elman RNN with $tanh$ or $ReLU$ non-linearity to an input sequence.   \n",
    "请求一个多层RNN（循环神经网络），它将对输入序列进行$tanh$或$ReLU$非线性运算。\n",
    "\n",
    "For each element in the input sequence, each layer computes the following function:   \n",
    "对于输入序列的每一个元素，每层都进行如下公司的运算：\n",
    "\n",
    " $$ h_t = tanh(W_{ih}x_t + b_{ih} + W_{hh}h_{t-1} + b_{hh}) $$\n",
    " \n",
    " where $h_t$ is the hidden state at time $t$, $x_t$ is the input at time $t$, and $h_{(t-1)}$ is the hidden state of the previous layer at time $t-1$ or the initial hidden state at time $0$. If `nonlinearity` is `relu`, then $ReLU$ is used instead of $tanh$.   \n",
    " 其中，$h_t$是$t$时刻的隐含状态，$x_t$是$t$时刻的输入，而$h_{(t-1)}$则是$t-1$时刻的隐含状态，该隐含状态的初始值为0.如果`nonlinearity`是`relu`，则用$ReLU$函数替换$tanh$函数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parameters**:   \n",
    "**参数**:\n",
    "\n",
    "* **input_size** – The number of expected features in the input $x$ 【输入$x$的特征数，输入向量$x$的维度数，输入的个数】\n",
    "* **hidden_size** – The number of features in the hidden state $h$ 【隐藏层神经元的个数】\n",
    "* **num_layers** – Number of recurrent layers. E.g., setting `num_layers=2` would mean stacking two RNNs together to form a stacked RNN, with the second RNN taking in outputs of the first RNN and computing the final results. Default: 1【RNN的层数，如果设置`num_layers=2`，则意味着有两个RNN连接在一起，其中第二个RNN的输入为第一个RNN的输出。缺省值为1.】\n",
    "* **nonlinearity** – The non-linearity to use. Can be either '`tanh`' or '`relu`'. Default: '`tanh`'【作用函数，缺省值为'`tanh`'，如果设置成 '`relu`'，则作用函数为$ReLU$函数】\n",
    "* **bias** – If `False`, then the layer does not use bias weights *b_ih* and *b_hh*. Default: `True`【如果设置成`False`则隐藏层没有参数*b_ih*和*b_hh*，缺省值为】\n",
    "* **batch_first** – If `True`, then the input and output tensors are provided as $(batch, seq, feature)$. Default: `False`\n",
    "* **dropout** – If non-zero, introduces a Dropout layer on the outputs of each RNN layer except the last layer, with dropout probability equal to `dropout`. Default: 0\n",
    "* **bidirectional** – If `True`, becomes a bidirectional RNN. Default: `False`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inputs**: input, h_0\n",
    "\n",
    "* **input** of shape *(seq_len, batch, input_size)*: tensor containing the features of the input sequence. The input can also be a packed variable length sequence. See [torch.nn.utils.rnn.pack_padded_sequence()](https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pack_padded_sequence.html#torch-nn-utils-rnn-pack-padded-sequence) or [torch.nn.utils.rnn.pack_sequence()](https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pack_sequence.html#torch-nn-utils-rnn-pack-sequence) for details.\n",
    "\n",
    "* **h_0** of shape *(num_layers * num_directions, batch, hidden_size)*: tensor containing the initial hidden state for each element in the batch. Defaults to zero if not provided. If the RNN is bidirectional, num_directions should be 2, else it should be 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Outputs**: output, h_n\n",
    "\n",
    "* **output** of shape *(seq_len, batch, num_directions * hidden_size)*: tensor containing the output features (h_t) from the last layer of the RNN, for each $t$. If a [torch.nn.utils.rnn.PackedSequence](https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.PackedSequence.html#torch.nn.utils.rnn.PackedSequence) has been given as the input, the output will also be a packed sequence.  \n",
    "For the unpacked case, the directions can be separated using `output.view(seq_len, batch, num_directions, hidden_size)`, with forward and backward being direction $0$ and $1$ respectively. Similarly, the directions can be separated in the packed case.\n",
    "\n",
    "* **h_n** of shape *(num_layers * num_directions, batch, hidden_size)*: tensor containing the hidden state for t = seq_len.  \n",
    "Like output, the layers can be separated using `h_n.view(num_layers, num_directions, batch, hidden_size)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Shape**:\n",
    "\n",
    "* **Input1**: $(L, N, H_{in})$ tensor containing input features where $H_{in}=\\text{input_size}$ and $L$ represents a sequence length.\n",
    "\n",
    "* **Input2**: $(S, N, H_{out})$ tensor containing the initial hidden state for each element in the batch.  \n",
    "$H_{out}=\\text{hidden_size}$ Defaults to zero if not provided. where $S=\\text{num_layers} * \\text{num_directions}$ If the RNN is bidirectional, num_directions should be 2, else it should be 1.\n",
    "\n",
    "* **Output1**: $(L, N, H_{all})$ where $H_{all}=\\text{num_directions} * \\text{hidden_size}$\n",
    "\n",
    "* **Output2**: $(S, N, H_{out})$ tensor containing the next hidden state for each element in the batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Variables**\n",
    "\n",
    "* **~RNN.weight_ih_l[k]** – the learnable input-hidden weights of the k-th layer, of shape *(hidden_size, input_size)* for $k = 0$. Otherwise, the shape is *(hidden_size, num_directions * hidden_size)*\n",
    "\n",
    "* **~RNN.weight_hh_l[k]** – the learnable hidden-hidden weights of the k-th layer, of shape *(hidden_size, hidden_size)*\n",
    "\n",
    "* **~RNN.bias_ih_l[k]** – the learnable input-hidden bias of the k-th layer, of shape *(hidden_size)*\n",
    "\n",
    "* **~RNN.bias_hh_l[k]** – the learnable hidden-hidden bias of the k-th layer, of shape *(hidden_size)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**\n",
    "\n",
    "All the weights and biases are initialized from $\\mathscr{U}(-\\sqrt{k}, \\sqrt{k})$ where $k = \\frac{1}{\\text{hidden_size}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = nn.RNN(10, 20, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(10, 20, num_layers=2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上述写法不意义清楚，换个写法，如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = nn.RNN(input_size=10, hidden_size=20, num_layers=2, nonlinearity='relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(10, 20, num_layers=2)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.num_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'relu'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.nonlinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "随机生成一个输入，其中`seq_len=5`, `batch=3`, `input_size=10`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(5, 3, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.2136,  0.6550, -0.5866,  0.7904, -0.4175,  0.2324,  0.4426,\n",
       "          -0.1730,  0.2303,  1.3951],\n",
       "         [-0.0633, -0.0234,  1.4220,  0.7754,  0.4210, -0.2156, -0.0238,\n",
       "           0.8117, -1.1339,  0.3355],\n",
       "         [ 0.3425,  0.3564,  0.9073, -0.0297,  1.1188, -0.2755, -0.5922,\n",
       "          -1.9047,  1.8543, -0.7428]],\n",
       "\n",
       "        [[-0.5415,  0.8176, -0.7917,  2.6023,  0.9393, -0.2480,  0.5148,\n",
       "           0.0495,  0.5244, -0.8879],\n",
       "         [-0.6655, -0.7050,  0.0285, -1.6590, -0.8466,  1.1517, -0.4227,\n",
       "          -0.6335,  1.0067, -1.0237],\n",
       "         [-2.4608,  0.9272, -0.8395,  0.2601, -0.0750, -0.0074,  0.5788,\n",
       "          -0.5884,  0.5253, -0.4161]],\n",
       "\n",
       "        [[-0.3016,  0.3559,  0.3049,  1.0602, -1.6101, -1.2519,  1.3368,\n",
       "           1.3935, -0.6285,  2.2198],\n",
       "         [ 1.4819, -1.1124, -0.8175,  0.0967, -1.6808, -0.5923,  2.0534,\n",
       "           0.8784, -0.8851, -0.3817],\n",
       "         [ 0.9969,  1.4029, -0.3292, -0.6317, -1.6539, -1.1570, -0.1709,\n",
       "          -0.7214, -0.5851,  1.0806]],\n",
       "\n",
       "        [[ 0.5875,  0.1916, -0.7831, -1.0263,  0.7372,  0.9670, -0.7466,\n",
       "           0.3191,  0.4756, -1.2518],\n",
       "         [ 1.8096, -1.1306,  0.5981, -0.7322,  1.7404,  1.8209, -0.5662,\n",
       "          -1.0406,  1.3863, -1.8173],\n",
       "         [-0.4196,  0.4075, -0.9910, -0.3376,  0.2966, -0.4793,  0.5446,\n",
       "           0.8823, -0.2569, -1.4703]],\n",
       "\n",
       "        [[-1.1294, -1.1255, -1.2265,  2.9947, -0.8064,  0.7995,  0.5285,\n",
       "           0.1882, -0.3865, -0.0067],\n",
       "         [-0.2540,  1.2345, -1.4976,  1.1491, -0.0040,  1.1745, -0.6992,\n",
       "          -1.6769, -1.6683, -0.1379],\n",
       "         [-1.3966,  0.9489, -1.2017, -0.2349, -2.4955,  1.0635, -0.8093,\n",
       "          -0.4576,  0.3093,  1.5132]]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3, 10])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "h0 = torch.randn(2, 3, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.7005,  2.0622,  0.2596,  1.1244, -0.0030, -0.8713,  1.3854,\n",
       "          -0.3751, -0.4079, -0.8769, -0.5297, -1.0469,  0.7056, -0.5951,\n",
       "          -1.5194, -0.6982,  1.7719,  0.8174, -0.0060, -1.8900],\n",
       "         [-0.7312,  0.7778, -0.5811, -0.4257, -0.8034, -0.8660,  1.5157,\n",
       "          -0.7403,  1.1677,  0.5809,  0.4522, -0.4620, -0.9990,  0.0904,\n",
       "           0.8183, -0.2081,  0.7247, -0.7790,  0.9893, -0.8280],\n",
       "         [-1.0413, -0.3022, -1.2148, -1.7313,  0.2203, -0.5146,  0.6175,\n",
       "          -0.6839, -0.0307,  1.6719,  0.4437, -0.2275,  1.3126, -0.7540,\n",
       "          -0.0356, -0.8927,  2.0019,  0.2936,  0.8306, -0.5191]],\n",
       "\n",
       "        [[ 0.8618,  2.8280, -1.4003,  0.4045, -0.8874,  1.1740,  2.6002,\n",
       "           0.8753,  1.3151, -1.4312,  2.0962,  0.8373,  0.3204, -0.2359,\n",
       "           0.7882, -1.2130,  1.5117, -2.1493, -2.0501,  1.1786],\n",
       "         [ 0.6501, -1.2137, -0.4433,  0.6859, -0.3681, -1.8112,  1.0084,\n",
       "           0.2967,  1.4405, -0.7480, -0.3950, -1.4791,  0.0060,  0.4411,\n",
       "           1.8298,  1.0974,  0.5301, -0.7734, -0.5644, -1.5995],\n",
       "         [-0.2736, -0.1809,  0.3379, -1.2908, -0.1937,  0.5925,  0.4469,\n",
       "           0.7878, -0.1849,  1.0120, -1.6483, -0.3940,  0.8868,  0.1294,\n",
       "          -0.8280,  0.8066, -0.9276,  0.5667,  0.8485,  0.5342]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, hn = rnn(input, h0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.0671e-01,  6.3203e-01, -1.4205e-01, -4.5679e-01,  4.9430e-01,\n",
       "           4.1664e-04, -2.2096e-01,  1.6742e-01, -1.5266e-01, -2.8774e-01,\n",
       "           5.0801e-01, -3.2709e-01,  1.5137e-01, -1.9688e-01,  6.6191e-01,\n",
       "           3.7101e-01, -1.6490e-01, -1.5713e-01,  3.3369e-02,  5.4381e-03],\n",
       "         [-4.0392e-01,  7.4687e-01, -3.6658e-01, -6.0945e-01,  1.7619e-01,\n",
       "          -5.1696e-01, -1.3466e-01,  4.9498e-01, -1.8346e-01, -2.3167e-01,\n",
       "          -1.2358e-02,  1.6410e-01, -2.3573e-02, -1.1894e-01,  4.8816e-01,\n",
       "           7.9178e-01,  3.0626e-01,  1.4387e-02,  8.6952e-02, -6.5329e-02],\n",
       "         [-4.9836e-01,  4.7920e-02, -4.2825e-01, -2.1469e-01,  2.6080e-01,\n",
       "          -1.2441e-01, -9.6232e-03,  4.6136e-01, -5.9921e-01, -3.0484e-01,\n",
       "          -2.2815e-01, -3.4020e-02, -9.3360e-01,  4.2591e-01,  2.8626e-01,\n",
       "           5.1743e-01,  1.1075e-01,  8.6932e-01, -1.5866e-02,  2.9688e-01]],\n",
       "\n",
       "        [[ 4.9944e-01, -3.9954e-02, -1.2648e-01,  9.3358e-03,  3.0234e-02,\n",
       "          -2.1879e-01, -4.9727e-01,  6.9419e-01, -3.3017e-02, -2.1212e-01,\n",
       "          -8.7661e-02, -1.5813e-01, -3.8766e-01,  1.4440e-01, -5.1587e-01,\n",
       "          -8.9033e-02,  5.4734e-01,  3.0830e-01,  9.3245e-02, -2.3153e-01],\n",
       "         [ 4.8506e-01, -8.5501e-03,  2.1291e-01,  4.1953e-01,  2.4822e-01,\n",
       "          -3.5170e-01, -3.5316e-01,  1.4168e-01, -1.7363e-01, -8.7513e-02,\n",
       "          -5.5902e-01, -1.3752e-01, -4.8010e-01,  4.8064e-01, -4.3887e-01,\n",
       "           4.3497e-02,  1.1149e-01,  3.0724e-01,  2.5430e-01, -7.5160e-02],\n",
       "         [ 3.1156e-01,  3.7008e-01, -2.3743e-01,  4.6929e-01,  1.9685e-01,\n",
       "           5.2374e-02,  3.6897e-01,  3.1499e-01,  6.8004e-02, -1.1168e-01,\n",
       "          -7.4534e-01, -4.3094e-02, -1.0017e-01,  4.9716e-01, -2.0399e-02,\n",
       "          -2.6848e-01, -3.8158e-01,  1.6509e-01,  4.3068e-01,  3.2459e-02]]],\n",
       "       grad_fn=<StackBackward>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.5825,  0.7571, -0.4633, -0.8861, -0.4963,  0.6599,  0.8740,\n",
       "           0.5617, -0.6960, -0.0864,  0.3847,  0.0574,  0.0355,  0.5923,\n",
       "           0.9324, -0.6560, -0.9243, -0.6949, -0.6292,  0.4132],\n",
       "         [-0.4413,  0.1195, -0.6355, -0.0180, -0.6298,  0.0630,  0.7187,\n",
       "           0.1938, -0.7252,  0.5678, -0.8940, -0.2355,  0.5314,  0.4671,\n",
       "          -0.3629, -0.9565, -0.8289,  0.6665, -0.4162,  0.6056],\n",
       "         [ 0.4981, -0.0386,  0.4446,  0.6393,  0.2247, -0.3710,  0.7947,\n",
       "           0.8055,  0.2164,  0.8039,  0.1271, -0.2050, -0.6548, -0.8605,\n",
       "          -0.4928,  0.4536,  0.6726,  0.0681,  0.2140, -0.4608]],\n",
       "\n",
       "        [[ 0.6615,  0.5527, -0.5354, -0.6154,  0.1578, -0.1347,  0.1343,\n",
       "           0.5307, -0.1963, -0.1883,  0.6901, -0.1787, -0.0157, -0.6794,\n",
       "           0.3095,  0.4369,  0.5052,  0.1298, -0.5970, -0.0251],\n",
       "         [ 0.7091,  0.5332, -0.1371, -0.0753,  0.3985, -0.5981, -0.0085,\n",
       "           0.7076,  0.0055, -0.3812,  0.2159, -0.1415, -0.5214, -0.2694,\n",
       "          -0.5465,  0.7622,  0.5365, -0.1138, -0.5283, -0.5132],\n",
       "         [ 0.2359,  0.5115,  0.2084, -0.1668,  0.0657,  0.3357, -0.1494,\n",
       "           0.4276, -0.1435, -0.6328, -0.6469,  0.3344, -0.1543,  0.4674,\n",
       "           0.3863, -0.0796, -0.1689, -0.0774,  0.1233, -0.4791]],\n",
       "\n",
       "        [[ 0.4471,  0.2410,  0.3534,  0.4221, -0.2095,  0.2542,  0.2154,\n",
       "          -0.0994, -0.1024, -0.0648, -0.6334,  0.1400,  0.0335,  0.5717,\n",
       "           0.2478, -0.3708, -0.3152,  0.0669,  0.4424, -0.0101],\n",
       "         [ 0.1773,  0.3314, -0.3650,  0.6261,  0.0012,  0.2227,  0.1179,\n",
       "           0.3145, -0.0053,  0.0336, -0.7661, -0.5390, -0.3676,  0.7389,\n",
       "           0.1110, -0.3151, -0.2589,  0.0412,  0.3804,  0.5028],\n",
       "         [ 0.0514,  0.1153, -0.5040, -0.1155, -0.1172,  0.3489,  0.1150,\n",
       "           0.7690,  0.0661,  0.1820, -0.1426, -0.4194, -0.2913, -0.3824,\n",
       "          -0.4760, -0.4610,  0.7179,  0.0184, -0.1940,  0.2185]],\n",
       "\n",
       "        [[ 0.3980,  0.4898, -0.4223, -0.2276,  0.2534, -0.3693, -0.0448,\n",
       "           0.6230,  0.0778,  0.1355, -0.1985, -0.0826,  0.1043,  0.2340,\n",
       "          -0.6415, -0.4547,  0.0625,  0.3297,  0.1942, -0.5580],\n",
       "         [ 0.1679,  0.5589, -0.5706, -0.0284,  0.6662, -0.3138, -0.2513,\n",
       "           0.3721, -0.3308,  0.5632, -0.0424, -0.7546, -0.0910,  0.3030,\n",
       "          -0.6866,  0.0828,  0.3434,  0.2654, -0.1357, -0.1442],\n",
       "         [ 0.5172,  0.1736,  0.3271, -0.1320,  0.1688, -0.0910,  0.0143,\n",
       "           0.3500, -0.1196, -0.1346,  0.0185,  0.1540,  0.2612, -0.1310,\n",
       "          -0.0736,  0.2683,  0.2126, -0.1815, -0.4465, -0.5122]],\n",
       "\n",
       "        [[ 0.4994, -0.0400, -0.1265,  0.0093,  0.0302, -0.2188, -0.4973,\n",
       "           0.6942, -0.0330, -0.2121, -0.0877, -0.1581, -0.3877,  0.1444,\n",
       "          -0.5159, -0.0890,  0.5473,  0.3083,  0.0932, -0.2315],\n",
       "         [ 0.4851, -0.0086,  0.2129,  0.4195,  0.2482, -0.3517, -0.3532,\n",
       "           0.1417, -0.1736, -0.0875, -0.5590, -0.1375, -0.4801,  0.4806,\n",
       "          -0.4389,  0.0435,  0.1115,  0.3072,  0.2543, -0.0752],\n",
       "         [ 0.3116,  0.3701, -0.2374,  0.4693,  0.1968,  0.0524,  0.3690,\n",
       "           0.3150,  0.0680, -0.1117, -0.7453, -0.0431, -0.1002,  0.4972,\n",
       "          -0.0204, -0.2685, -0.3816,  0.1651,  0.4307,  0.0325]]],\n",
       "       grad_fn=<StackBackward>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
